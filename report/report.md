# 双目成像实验报告

## 封面

g。自己先在word里做一张，包括分工：

曾富楠：40%，程序框架和最小生成树聚合
宣思诚：30%，NCC计算及双边滤波聚合
李泽奇：30%，双目校正和偏差值优化

## 问题描述

双目成像指的是通过两个有固定距离的摄像头拍摄的两张有微小差别的照片，计算出各个位置上图像的偏移量，再通过距离=焦距/偏移量就可以判断视野中物体的距离。双目成像也是人眼中判断距离的主要方法。在计算机中，双目成像的过程也是类似的，首先获取左右两张图像，通过各种方法计算在偏移量不同时两张图像上各点的相似程度，然后通过滤波等方法聚合相似度，避免局部的误差过大，最后选出每个位置上的最佳偏移量。

在这个实验中，我们使用的数据来自Middlebury 2021数据集。相比于其他数据集，这个数据集的图像大小达到1080p，非常巨大，且场景中的物品非常复杂，包含了大量细节或者无纹理的物体，在性能和精度上都是双目成像算法的巨大考验。为此，我们使用了NCC衡量相似度，分别使用了双边滤波和最小生成树滤波的方法进行聚合，在最后还检查了左右深度的一致性。

同时，我们还自己购买了双目摄像头，制备数据集，使用Bouguet算法进行双目标定，利用校正的图片，在拍摄的图像上进行了双目成像。

## 实现细节

### 双目标定和校正

#### 实现方法

​		这部分包括两个步骤，双目标定与双目校正。其中双目标定是双目校正的基础，它为双目校正的过程提供了外参R（旋转矩阵）与T（平移矩阵），以及左右两个相机的内参矩阵K和畸变矩阵D。通过这六个元素，双目校正环节就可以进一步得到校正旋转矩阵Rrect以及投影矩阵P，来完成左右两张图的校正匹配，并将他们投影到新的坐标上了。但同时双目标定也需要对图像进行一些初始的处理才能使用。

​        我分别用两种方式来进行双目标定与双目矫正。在双目标定方面，我用cv库自带的函数findChessboardCorners，cornerSubPix，calibrateCamera编写程序来计算双目标定需要的参数，再用stereocalibrate来算出双目矫正需要的参数。同时使用MATLAB的stereo camera calibrator来计算前一种方法中同样的图片来获得用作为对照组的参数。在双目矫正方面，我根据bouguet算法自行编写了计算校正旋转矩阵Rrect和投影矩阵P的函数，同时使用stereoRectify函数来作为对照。

#### 双目标定

双目标定就是利用已知世界坐标系和图像坐标系的对应关系，计算出双目相机在当前位置关系下的参数信息。 

双目标定的全部过程其实可以分为：单目标定准备、单目标定、以及双目标定三个部分。首先需要准备并拍摄好标定板的图片，通过对这些图片进行角点标定与分析，我们就可以获得许多个角点坐标、对这些角点坐标进行精度提高后，再结合以标定板的实际参数，就可以通过单目标定确定左右两个相机的参数了。最后就可以运用左右相机的参数轻松进行双目标定。

​		通过cv库函数实现的双目标定最终获得的矩阵为

​		通过Matlab计算得出的参数矩阵为

#### 双目矫正

双目校正的作用就是要把消除畸变后的两幅图像严格地行对应，使得两幅图像的对极线恰好在同一水平线上。本次项目中，我使用Bouguet算法，对双目标定获得的R（旋转矩阵），T（平移矩阵），KL（左内参矩阵），KR（右内参矩阵）矩阵进行了处理，进而得到了Rrect（矫正旋转矩阵）以及PL、PR（左右投影矩阵）。

​		自行编写函数得到的矩阵

​		用stereoRectify函数获得的对照矩阵

#### 最终矫正效果

​		使用自行编写的矫正程序获得的图片

​		使用stereoRectify矫正得到的图像

#### 遇到的问题

1.双目矫正过程中，最开始使用自行编写的投影代码，发现投影后图像误差过大，故最终决定只自行实现stereoRectify函数，投影部分改为使用initUndistorRectifyMap与remap这两个cv库自带函数来实现。

2.编写Rrect（矫正旋转矩阵）和P（投影矩阵）时，使用eigen库的函数进行计算，但在最后投影时使用的时cv库函数，无法一起使用，后通过使用eigen2cv以及cv2eigen函数完成不同库的矩阵的转换。

3.由于对stereoCalibrate的函数功能不熟悉，误以为其本身可以直接自行算出两个摄像头的内参矩阵并输出，导致实际上一直使用的内参矩阵只是一个单位矩阵，造成输出图像严重变形。后添加了calibrateCamera这一单目相机参数计算函数，并将其输出的参数赋给stereoCalibrate，才解决了这一问题。

### 输入输出

本实验中使用Middlebury 2021数据集，这个数据集包括三部分

1. 测试描述，包括测试用的像素内参、图像大小、估计最大偏差值和实际最大最小偏差值（仅供验证）。
2. 双目校正后的左右图像。
3. 左右图像对应的偏差值的真值。

其中，真值使用PFM格式编码，根据http://netpbm.sourceforge.net/doc/pfm.html，这个格式包括文件开头"Pf"或者"PF"，两个代表图像尺寸的整数，一个代表大小端和缩放倍数的浮点数。上述三个数字以文本表示，结束后有一个换行符0x0A。在开头后是若干个IEEE 754 32位浮点数，直接读入`cv::Mat`的数据指针即可。但要注意的是，这个数据的原点在左下方，与OpenCV（左上）不同，需要关于x轴进行翻转。

### NCC计算

NCC（Normalized CrossCorrelation）是用于归一化待匹配目标之间的相关程度。相比于直接进行像素值相减的方法，NCC将左右像素的差距根据均值和标准差进行标准化，避免了亮度等的干扰。

这里比较的是原始像素。通过在待匹配像素位置$p$构建邻域匹配窗口，与目标像素位置$p^\prime$同样构建邻域匹配窗口的方式建立目标函数来对匹配窗口进行度量相关性。这里构建相关窗口的前提是两帧图像之间已经校正到水平位置，即光心处于同一水平线上，此时极线是水平的，否则匹配过程只能在倾斜的极线方向上完成，这会消耗更多的计算资源。
$$
C(u,v,d) = \frac{\sum_{x=u-\varrho}^{u+\varrho}\sum_{y=v-\varrho}^{v+\varrho}I_l(x,y)I_r(x-d,y)-n\mu_l\mu_r}{n\sigma_l\sigma_r}
$$
NCC部分的计算依托于左右图像的灰度值，因为RGB格式无法选择通用有效的值进行计算，因此程序在进行运算前将左右图全部转化为灰度图，所有需要调用左右图像像素值的部分调用结果均为灰度值。

#### 计算过程

式中的$\sum_{x=u-\varrho}^{u+\varrho}\sum_{y=v-\varrho}^{v+\varrho}I_l(x,y)I_r(x-d,y)$部分因为左右图的窗口值也就是像素间隔的设定始终维持在一个动态的情况下，因此这部分的计算无法通过前缀和这类优化，因此只能选择OMP进行并行运算以提高运算速度。而均值部分	$\mu_l\mu_r$和标准差$\sigma_l\sigma_r$部分则因为与窗口值无关，在整个计算的过程中维持恒定，因此可以对其进行部分优化。我们的程序使用了二维前缀和（积分图）的形式对其进行优化，在需要遍历窗口值的计算部分之前将所有均值以及标准差全部计算完成，这样就方便了后续在程序中调用。

要注意的是，前缀和必须使用整数数据类型而不是浮点数据类型。这是因为我们需要大量计算两个相邻的大数间的差距，如果使用浮点数表示，则这个差距可能因为两个数字太大而被滤去，造成非常大的误差。但计算机上的整数都是表示模$2^N$环上的数，低位不会被舍去，满足交换律和结合律，不存在误差。

式中的I代表像素强度，取值即为上述的图像灰度值，范围[0,255]。式中$\varrho$的值取8，相对扩大了像素块的大小，这样有利于保证相关度的有效性，使其更加准确。计算结果储存在三维矩阵中方便后续调用计算。

### 双边滤波

双边滤波是一种非线性的滤波方法，是结合图像的空间邻近度和像素值相似度的一种折中处理，同时考虑空域信息和灰度相似性，达到保边去噪的目的。具有简单、非迭代、局部的特点，可以做边缘保存。

#### 基本思路

同时考虑像素点的空域信息和值域信息。即先根据像素值对要用来进行滤波的邻域做一个分割或分类，采用加权平均的方法，用周边像素亮度值的加权平均代表某个像素的强度，所用的加权平均基于高斯分布。最重要的是，双边滤波的权重不仅考虑了像素的欧氏距离，还考虑了像素范围域中的辐射差异，在计算中心像素的时候同时考虑这两个权重。

在平坦区域，临近像素的像素值的差值较小，对应值域权重接近于1，此时空域权重起主要作用，相当于直接对此区域进行高斯模糊。因此，平坦区域相当于进行高斯模糊。在边缘区域，临近像素的像素值的差值较大，对应值域权重接近于0，导致此处核函数下降，当前像素受到的影响就越小，从而保持了原始图像的边缘的细节信息。

#### 计算过程

双边滤波的公式如下，其中$\omega_r$为关于$x$和$y$的正态分布，$\omega_d$为关于$I(x)$和$I(y)$的正态分布

$$
C^A(u,v,d) = \frac{\sum_{x=u-\rho}^{u+\rho}\sum_{y=v-\rho}^{v+\rho}\omega_d(x,y)\omega_r(x,y)C(x,y,d)}{\sum_{x=u-\rho}^{u+\rho}\sum_{y=v-\rho}^{v+\rho}\omega_d(x,y)\omega_r(x,y)}
$$

计算中每次选定一个像素点，并以该像素点为中心向周围扩展出一个像素块，像素块中每个像素的像素强度和中心点的像素强度差值将直接影响计算过程中的权重，最终与对应的NCC部分计算结果进行运算。以此为基本思路完成整个滤波过程。

相较于NCC部分，这部分的运算时间可能达到其十倍甚至百倍。面对如此巨大的运算量必须对其进行优化，但由式中可以看出，每一个像素块的运算结果与当前像素块中心的像素强度有关，因此像素强度的差值也会随着像素块中心点的变化而持续变化，无法使用前缀和一类的优化方案，只能对其使用OMP进行并行计算，以此来减少运算时间。即便如此，这部分的计算量依旧庞大，整个程序最终的运算时间依旧很大程度上取决于该部分的运算时间。

### 最小生成树聚合

最小生成树聚合是论文A non-local cost aggregation method for stereo matching中使用的一种类似双边滤波的聚合计算方法。这个方法的特点利用的数据结构比较复杂，但计算量很小，且表现不错，适合于CPU上进行计算。

#### 数学模型

作为一种基于生成树的图像滤波，最小生成树首先要求将像素点间的连通关系转换为生成树（spanning tree）的结构，即把图片中的像素和上下左右的相邻像素连接作为无向图，去掉若干边后，使得任意两个像素间只有一条可能的路径，且所有权重的合最小。

可以使用Prim算法计算最小生成树。按权重从小到大遍历所有边，遍历过程中，如果一条边的两端不在同一树中，则将这条边两端连接，加入生成树中，并且这条边在第二步不再遍历。对于RGB图片，权重指的是两个像素间RGB三个值的偏差中最大的一个，取值范围$[0,255]$。

构成生成树后，ST算法在全图上计算一个聚合的值：

$$
C^A(p) = \sum_{q\in I}{S(p, q)C(q)}
$$

其中$C^A(p)$为p点聚合后的cost，$C(q)$为q点聚合前的cost，$I$为图片上所有像素的集合，$S(p, q)$是图上这两个点的距离的函数，定义为

$$
S(p,q)=\exp{\left(-\frac{D(p,q)}{\sigma}\right)}
$$

$D(p,q)$为p、q两点间的距离，以生成树上这两间边的权重的和衡量。

若任意指定一个点为根节点，把生成树转换为有方向的树，则上述$C^A(p)$有一个计算量很小且递归的计算方法。定义$C^{A\uparrow}(p)=\sum_{q\in\operatorname{subtree}(p)}{S(p, q)C(q)}$为p点的子树中所有点对p点的聚合值的贡献，由于当b点在a、c两点间时，$S(a,c)=S(a,b)\cdot S(b,c)$，有方程

$$
\begin{align}
    C^{A\uparrow}(p) &= C(p) + \sum_{q\in\operatorname{child}(p)}{S(p,q)C^{A\uparrow}(q)}\\
    C^A(p) &= S(\operatorname{parent}(p),p)C^A(\operatorname{parent}(p))+(1-S(\operatorname{parent}(p),p)^2)C^{A\uparrow}(p)
\end{align}
$$

根据边界条件，p为叶节点时$C^{A\uparrow}(p)=C(p)$，可以递归地自底向上计算出各节点的$C^{A\uparrow}$，又有p为根节点时$C^A(p)=C^{A\uparrow}(p)$，可以递归地自顶向下计算出各节点的$C^A$。

#### 有向图的编码

实现上述算法重点是需要在图这样一个连接比较稀疏的结构中简单地表示边和节点，以及如何判断两个节点是否已连接。其余的过程按照Prim算法即可，生成完后再将无向图转换为有向图。

为了节约空间及更好的空间连续性可能带来的缓存性能优化，边用32位的位域表示，其中最高的8位表示权重，次高位表示是边的方向是横向还是纵向，其余的23位用于表示地址较小的像素的偏移地址，23位范围内大约可以表示4K，即3840x2160，足以满足实验的要求。权重直接嵌入到边的数据结构中，这样每次判断时不需要再去查找原图像，提高性能。

而无向图通过一个4位整数表示，四个比特分别表示上下左右四个方向上是否有相邻的边。树还需要一个额外的整数用于指示父节点的方向避免死循环，因此另有2个比特用于表示方向。

另外，判断两个点是否已连接需要使用到并查集。由于像素的偏移坐标是连续的，因此可以使用数组直接存储并查集的父节点。由于涉及非常多的查询操作，并查集只使用简单的路径压缩进行优化也可以保证性能。路径压缩即每次查找时，把查询路径上所有节点的父节点都指向最终的父节点，使得下次查询时一步即可到达。

有了上述数据结构，可以使用Prim算法计算最小生成树了：

1. 生成所有的边，即除了最右的像素都生成向右的一条边，除了最下的像素都生成向下的一条边
2. 根据权重排序这些边。由于权重的访问是完全独立的，通过`std::executaion::par_unseq`说明使用可以并行化的`std::sort`进行排序。
3. 计算最小生成树。根据权重从小到大遍历各边，通过并查集判断遍历到的边是否连接两个未连通的节点，如果是则更新无向图，把这个节点加入无向图中，同时也更新并查集反应无向图的连通状况。
4. 将最小生成树改为有向图，即任意指定一节点为根节点，深度优先遍历各节点，确定父节点的方向。

#### 聚合

建立了树之后，聚合是比较简单的，只需要根据4个方向，从根节点开始逐个遍历所有的节点，首先计算$C^{A\uparrow}($，然后再计算$C^A$即可。但需要注意的是，由于遍历的深度可能非常非常深，不能使用系统栈，而是需要手动地编写状态机，这是比较复杂的，尤其是自底向上遍历时，还需要涉及复杂的状态储存。

但需要关注的是聚合过程中的数值稳定性。在$C^A(p) = S(\operatorname{parent}(p),p)C^A(\operatorname{parent}(p))+(1-S(\operatorname{parent}(p),p)^2)C^{A\uparrow}(p)$中，$C^A(\operatorname{parent}(p))$已经包含了$C^{A\uparrow}(p)$，在后面的计算中又减去$C^{A\uparrow}(p)$，由于浮点数的取整，左右并不严格相等。但舍去部分的占比通常不大，因此可以认为左右近似相等。但要注意的是，如果cost可能是nan，则会导致整个树都是nan，这是全局滤波不可避免的。

### 偏差值优化

偏差值的优化包括两个部分；偏差值选取和偏差值优化。

#### 偏差值选取

先前通过代价的计算与聚合，已经获得了左右两组图片在不同深度下的代价值，即cost，并且将这些cost储存在一个三维矩阵（x，y，d）中，接下来我们要做的就是处理这些cost数据，根据这它们选出图像上每一点处的最佳偏差值，并将最佳偏差值保存起来，输出一个二维的偏差值（视差）矩阵。

我在偏差值选取方面我使用了简单的Winner-Take-All算法，因为cost的性质为最大相关性代价，故而cost是越大越好。对于图像中的每一个点，从最小视差到最大视差，不断遍历其中的cost来找到最大的那一个，并记录下最大cost的偏差值，再将其储存到二维的偏差值矩阵里，便大功告成。

#### 偏差值优化

偏差值优化又包括两个步骤：左右一致性检查与子像素拟合。

首先是左右一致性检查，其本质为基于偏差值的一般性约束。其基本思想是：从代价聚合这步已经得到了左图像的视差图，现将左右图像互换位置，即左图像变成右图像，右图像变成左图像，这时候再重新做一次立体匹配，会得到新的左图像的视差图，这时比较左右图像同名点的视差，看视差是否一致，若一致，则满足一致性检查，否则不满足，这时就把不满足的点给剔除掉。实际上，我们对比较左右图像同名点的视差有一定的容忍程度，即不需要两者视差一致才保留，而是若两个视差值之间的差值若小于一定阈值，则满足唯一性约束被保留，反之则不满足唯一性约束而被剔除。

左右一致性检查又分为外部型检查和内部型检查。本项目中我选择使用的是内部型检查，其原理为：通过左影像的代价数组，来推算右影像的代价数组。左右相机对同一个物体拍摄了两张图片，那么着两张图片中应该存在着相互对应的点。通过其中一张图中点的位置和偏差值，我们就能轻松推断出另外一张图中相应点的位置。那么接下来我们只要根据阈值比较误差来确定去除还是保留就可以了。

在代码中通过将左图某点的横向坐标减去其偏差值就可以得到右图坐标，然后比对两者偏差值即可。

接着便是子像素拟合。通过代价矩阵得到的视差图是整像素精度的，这在许多应用中都是无法满足需求的。这时候我们需要对得到的视差图进行子像素拟合，让视差图的精度进一步提高。其本质就是拟合一个一元二次曲线。先前我们通过偏差值选取获得了一个二维的偏差值矩阵。这个矩阵中存储着图像中每个点处的最优偏差值。但正如上文所说，这些偏差值为整数，接下来我们要做的就是以该偏差值矩阵为基础，拟合出精度更高的浮点偏差值再储存回这个矩阵里。

找到偏差值矩阵某一点的偏执值。再在cost矩阵里找到其对应点。这时，通过与它本身（d）以及与它相邻的两个偏差值d+1和d-1中，我们可以获得三个cost值d.cost、(d-1).cost、(d+1).cost。以d为横坐标，cost为纵坐标，我们就可以拟合出一个一元二次曲线。此时这个二次曲线的顶点处的x坐标，即d值就是我们拟合出来的偏差值了。接下来只要将其代回偏差值矩阵便可。

#### 遇到的问题

1.偏差值选取过程中，因为弄混最小差分代价和最高相关代价而导致图片发生失真，通过将选取最小值改为选取最大值后该问题就得到了解决

2.偏差值优化过程中，默认初始阈值设定过小，导致图像出现大片黑色图斑，将阈值调高至10后问题得到较好的解决。

3.偏差值优化中，优化后的输出图片往往莫名出现斑马条纹状的干扰。后查明是在进行左右一致性检查时，左图坐标过小时再减去偏差值其实就得到负数，进而自动移动到上一行像素点的坐标，导致左右一致性检查出错，产生了许多错误的黑块。通过增加一个if语句比对坐标值与偏差值大小即可解决

4.偏差值优化中，发现图片子像素拟合效果不明显，后发现是使用不恰当if语句所导致，更改后恢复正常。

### 性能优化

双目成像是计算量非常大的任务，在未经优化的代码上，一幅图片可能需要数分钟的时间。因此，实验中还进行了性能优化的尝试：

#### 使用复杂度低的算法

本实验中选用的数据集为Middlebury 2021，该数据集中图像的分辨率为1920x1080，且左右偏差可达300像素，带来的计算量是非常大的。但我们使用的算法复杂度较低，减少了大尺寸图片的影响。比如我们使用了积分图优化NCC计算，这个算法的复杂度只和像素数有关，即图像尺寸放大为2倍后计算量为原来的4倍。而如果直接计算，则图像放大后相应的窗口大小也要放大，图像尺寸放大为2倍后计算量为原来的16倍。而最小生成树聚合也同样只和图像的像素数有关，图像尺寸放大为2倍后，偏差值也放大为2倍，计算量为原来的8倍，而如果是双边滤波，则滤波窗口同样要放大，计算量会变为原来的32倍。

#### 使用适合CPU的算法

由于我们选用CPU进行计算，因此要充分选择发挥CPU顺序执行能力的算法。在NCC计算部分，我们使用了前缀和，使得求和部分的计算量和求和区域大小无关。代价是前缀和的计算是高度顺序相关的，不能调换计算顺序。在聚合部分，我们使用了基于图的聚合方法，这个方法对内存的要求非常高，而且包含大量分支，是比较适合CPU的计算能力的。

#### 并行计算

实验中各个环节都涉及大量数值计算，这些计算都跟偏差值d关系不大，因此我们在所有遍历d的循环上都使用OMP进行了并行，充分利用CPU的多个核心。

#### 充分内联

在实验中我们发现，访问图像某一位置值的函数`Mat::at`并没有被内联，这使得大量的循环优化等没有实现。通过调整MSVC内联级别从`/O2`默认的`/Ob2`到更强的`/Ob3`，可以发现`Mat::at`被内联，使得程序速度提高了20%左右。

## 实验结果

### Middlebury 2021表现

### 自制数据集表现

## 应用背景分析或展望

双目视觉相较于投影式、全息照相式等三维成像技术而言，双目视觉成本更低、效率更高、结构更简单，因此在工业检测、机器人导航、医学机器成像、控制与检测位姿、军事、航空测绘等诸多领域均有广泛应用。例如构建自适应伺服系统，仿真机器人导航系统，多维度机械装置位姿检测等。相对更贴近我们日常生活的应用也有智能驾驶、虚拟现实技术方面的应用。

我们的程序计算速度较快，在Intel i7-10700 CPU上，不加左右校验时可以在3-4秒的时间计算一张1080p，左右差别200像素左右的图片，在实际应用中可以不采取清晰度这么高的图像进行计算，以Middlebury2003数据集为例，该数据集图像较小，计算量只有测试图像的1/70。同时我们的程序在计算过程中选取的窗口值范围是$[0,170]$，实际计算中窗口值范围可以有所收小，或者不必对窗口值进行连续计算，可以离散地选择其中有代表性的窗口值计算，并以此减小计算量。如果应用了上述两个方法，则计算量极大减小，可以实时进行。同时在并行计算方面，我们的程序只使用了OMP对其进行少量优化，并未使用SIMD指令，如果能增加这方面的优化，程序的运算速度还可以更上一层。

我们的程序实现了双目立体视觉算法，作为基础的三维成像技术在诸多领域均有广泛应用。同时，为了追求精度牺牲了一部分运算时间，也并未在并行程序上进行过多优化，这些问题在实际应用中可以对其进行优化以达到更快的计算时间效果。
