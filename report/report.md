# 双目成像实验报告

## 封面

g。自己先在word里做一张，包括分工：

曾富楠：40%，程序框架和最小生成树聚合
宣思诚：30%，NCC计算及双边滤波聚合
李泽奇：30%，双目校正和偏差值优化

## 问题描述

​		我们实现的项目是双目视觉。并且选择自行制备数据库，完成双目矫正，并最终实现双目视觉处理。

​		为此，我们购买了双目摄像头，自行配置了标定板并采集到图像，完成了数据库。并使用Bouguet算法完成了双目标定与双目矫正，随之完成了NCC计算，并且做出了双边滤波和最小生成树聚合两种方式来进行代价聚合；最后通过简单的WTA和子像素拟合完成了偏差值的选取和优化。

## 实现细节

### 双目标定和校正
#### 实现方法

​		这部分包括两个步骤，双目标定与双目校正。其中双目标定是双目校正的基础，它为双目校正的过程提供了外参R（旋转矩阵）与T（平移矩阵），以及左右两个相机的内参矩阵K和畸变矩阵D。通过这六个元素，双目校正环节就可以进一步得到校正旋转矩阵Rrect以及投影矩阵P，来完成左右两张图的校正匹配，并将他们投影到新的坐标上了。但同时双目标定也需要对图像进行一些初始的处理才能使用。

​        我分别用两种方式来进行双目标定与双目矫正。在双目标定方面，我用cv库自带的函数findChessboardCorners，cornerSubPix，calibrateCamera编写程序来计算双目标定需要的参数，再用stereocalibrate来算出双目矫正需要的参数。同时使用MATLAB的stereo camera calibrator来计算前一种方法中同样的图片来获得用作为对照组的参数。在双目矫正方面，我根据bouguet算法自行编写了计算校正旋转矩阵Rrect和投影矩阵P的函数，同时使用stereoRectify函数来作为对照。

#### 双目标定

双目标定就是利用已知世界坐标系和图像坐标系的对应关系，计算出双目相机在当前位置关系下的参数信息。 

双目标定的全部过程其实可以分为：单目标定准备、单目标定、以及双目标定三个部分。首先需要准备并拍摄好标定板的图片，通过对这些图片进行角点标定与分析，我们就可以获得许多个角点坐标、对这些角点坐标进行精度提高后，再结合以标定板的实际参数，就可以通过单目标定确定左右两个相机的参数了。最后就可以运用左右相机的参数轻松进行双目标定。

​		通过cv库函数实现的双目标定最终获得的矩阵为

​		通过Matlab计算得出的参数矩阵为

#### 双目矫正

双目校正的作用就是要把消除畸变后的两幅图像严格地行对应，使得两幅图像的对极线恰好在同一水平线上。本次项目中，我使用Bouguet算法，对双目标定获得的R（旋转矩阵），T（平移矩阵），KL（左内参矩阵），KR（右内参矩阵）矩阵进行了处理，进而得到了Rrect（矫正旋转矩阵）以及PL、PR（左右投影矩阵）。

​		自行编写函数得到的矩阵

​		用stereoRectify函数获得的对照矩阵

#### 最终矫正效果

​		使用自行编写的矫正程序获得的图片

​		使用stereoRectify矫正得到的图像

#### 遇到的问题

1.双目矫正过程中，最开始使用自行编写的投影代码，发现投影后图像误差过大，故最终决定只自行实现stereoRectify函数，投影部分改为使用initUndistorRectifyMap与remap这两个cv库自带函数来实现。

2.编写Rrect（矫正旋转矩阵）和P（投影矩阵）时，使用eigen库的函数进行计算，但在最后投影时使用的时cv库函数，无法一起使用，后通过使用eigen2cv以及cv2eigen函数完成不同库的矩阵的转换。

3.由于对stereoCalibrate的函数功能不熟悉，误以为其本身可以直接自行算出两个摄像头的内参矩阵并输出，导致实际上一直使用的内参矩阵只是一个单位矩阵，造成输出图像严重变形。后添加了calibrateCamera这一单目相机参数计算函数，并将其输出的参数赋给stereoCalibrate，才解决了这一问题。




### 输入输出

z。

### NCC计算

x。

### 双边滤波

x。

### 最小生成树聚合

最小生成树聚合是论文A non-local cost aggregation method for stereo matching中使用的一种类似双边滤波的聚合计算方法。这个方法的特点利用的数据结构比较复杂，但计算量很小，且表现不错，适合于CPU上进行计算。

#### 数学模型

作为一种基于生成树的图像滤波，最小生成树首先要求将像素点间的连通关系转换为生成树（spanning tree）的结构，即把图片中的像素和上下左右的相邻像素连接作为无向图，去掉若干边后，使得任意两个像素间只有一条可能的路径，且所有权重的合最小。

可以使用Prim算法计算最小生成树。按权重从小到大遍历所有边，遍历过程中，如果一条边的两端不在同一树中，则将这条边两端连接，加入生成树中，并且这条边在第二步不再遍历。对于RGB图片，权重指的是两个像素间RGB三个值的偏差中最大的一个，取值范围$[0,255]$。

构成生成树后，ST算法在全图上计算一个聚合的值：

$$
C^A(p) = \sum_{q\in I}{S(p, q)C(q)}
$$

其中$C^A(p)$为p点聚合后的cost，$C(q)$为q点聚合前的cost，$I$为图片上所有像素的集合，$S(p, q)$是图上这两个点的距离的函数，定义为

$$
S(p,q)=\exp{\left(-\frac{D(p,q)}{\sigma}\right)}
$$

$D(p,q)$为p、q两点间的距离，以生成树上这两间边的权重的和衡量。

若任意指定一个点为根节点，把生成树转换为有方向的树，则上述$C^A(p)$有一个计算量很小且递归的计算方法。定义$C^{A\uparrow}(p)=\sum_{q\in\operatorname{subtree}(p)}{S(p, q)C(q)}$为p点的子树中所有点对p点的聚合值的贡献，由于当b点在a、c两点间时，$S(a,c)=S(a,b)\cdot S(b,c)$，有方程

$$
\begin{align}
    C^{A\uparrow}(p) &= C(p) + \sum_{q\in\operatorname{child}(p)}{S(p,q)C^{A\uparrow}(q)}\\
    C^A(p) &= S(\operatorname{parent}(p),p)C^A(\operatorname{parent}(p))+(1-S(\operatorname{parent}(p),p)^2)C^{A\uparrow}(p)
\end{align}
$$

根据边界条件，p为叶节点时$C^{A\uparrow}(p)=C(p)$，可以递归地自底向上计算出各节点的$C^{A\uparrow}$，又有p为根节点时$C^A(p)=C^{A\uparrow}(p)$，可以递归地自顶向下计算出各节点的$C^A$。

#### 有向图的编码

实现上述算法重点是需要在图这样一个连接比较稀疏的结构中简单地表示边和节点，以及如何判断两个节点是否已连接。其余的过程按照Prim算法即可，生成完后再将无向图转换为有向图。

为了节约空间及更好的空间连续性可能带来的缓存性能优化，边用32位的位域表示，其中最高的8位表示权重，次高位表示是边的方向是横向还是纵向，其余的23位用于表示地址较小的像素的偏移地址，23位范围内大约可以表示4K，即3840x2160，足以满足实验的要求。权重直接嵌入到边的数据结构中，这样每次判断时不需要再去查找原图像，提高性能。

而无向图通过一个4位整数表示，四个比特分别表示上下左右四个方向上是否有相邻的边。树还需要一个额外的整数用于指示父节点的方向避免死循环，因此另有2个比特用于表示方向。

另外，判断两个点是否已连接需要使用到并查集。由于像素的偏移坐标是连续的，因此可以使用数组直接存储并查集的父节点。由于涉及非常多的查询操作，并查集只使用简单的路径压缩进行优化也可以保证性能。路径压缩即每次查找时，把查询路径上所有节点的父节点都指向最终的父节点，使得下次查询时一步即可到达。

有了上述数据结构，可以使用Prim算法计算最小生成树了：

1. 生成所有的边，即除了最右的像素都生成向右的一条边，除了最下的像素都生成向下的一条边
2. 根据权重排序这些边。由于权重的访问是完全独立的，通过`std::executaion::par_unseq`说明使用可以并行化的`std::sort`进行排序。
3. 计算最小生成树。根据权重从小到大遍历各边，通过并查集判断遍历到的边是否连接两个未连通的节点，如果是则更新无向图，把这个节点加入无向图中，同时也更新并查集反应无向图的连通状况。
4. 将最小生成树改为有向图，即任意指定一节点为根节点，深度优先遍历各节点，确定父节点的方向。

#### 聚合

建立了树之后，聚合是比较简单的，只需要根据4个方向，从根节点开始逐个遍历所有的节点，首先计算$C^{A\uparrow}($，然后再计算$C^A$即可。但需要注意的是，由于遍历的深度可能非常非常深，不能使用系统栈，而是需要手动地编写状态机，这是比较复杂的，尤其是自底向上遍历时，还需要涉及复杂的状态储存。

但需要关注的是聚合过程中的数值稳定性。在$C^A(p) = S(\operatorname{parent}(p),p)C^A(\operatorname{parent}(p))+(1-S(\operatorname{parent}(p),p)^2)C^{A\uparrow}(p)$中，$C^A(\operatorname{parent}(p))$已经包含了$C^{A\uparrow}(p)$，在后面的计算中又减去$C^{A\uparrow}(p)$，由于浮点数的取整，左右并不严格相等。但这里实际上表现为两个正数相加，即使有浮点误差影响也不大。但要注意的是，如果cost可能是nan，则会导致整个树都是nan，这是全局滤波不可避免的。

### 偏差值优化

偏差值的优化包括两个部分；偏差值选取和偏差值优化。

#### 偏差值选取

先前通过代价的计算与聚合，已经获得了左右两组图片在不同深度下的代价值，即cost，并且将这些cost储存在一个三维矩阵（x，y，d）中，接下来我们要做的就是处理这些cost数据，根据这它们选出图像上每一点处的最佳偏差值，并将最佳偏差值保存起来，输出一个二维的偏差值（视差）矩阵。

我在偏差值选取方面我使用了简单的Winner-Take-All算法，因为cost的性质为最大相关性代价，故而cost是越大越好。对于图像中的每一个点，从最小视差到最大视差，不断遍历其中的cost来找到最大的那一个，并记录下最大cost的偏差值，再将其储存到二维的偏差值矩阵里，便大功告成。

#### 偏差值优化

偏差值优化又包括两个步骤：左右一致性检查与子像素拟合。

首先是左右一致性检查，其本质为基于偏差值的一般性约束。其基本思想是：从代价聚合这步已经得到了左图像的视差图，现将左右图像互换位置，即左图像变成右图像，右图像变成左图像，这时候再重新做一次立体匹配，会得到新的左图像的视差图，这时比较左右图像同名点的视差，看视差是否一致，若一致，则满足一致性检查，否则不满足，这时就把不满足的点给剔除掉。实际上，我们对比较左右图像同名点的视差有一定的容忍程度，即不需要两者视差一致才保留，而是若两个视差值之间的差值若小于一定阈值，则满足唯一性约束被保留，反之则不满足唯一性约束而被剔除。

左右一致性检查又分为外部型检查和内部型检查。本项目中我选择使用的是内部型检查，其原理为：通过左影像的代价数组，来推算右影像的代价数组。左右相机对同一个物体拍摄了两张图片，那么着两张图片中应该存在着相互对应的点。通过其中一张图中点的位置和偏差值，我们就能轻松推断出另外一张图中相应点的位置。那么接下来我们只要根据阈值比较误差来确定去除还是保留就可以了。

在代码中通过将左图某点的横向坐标减去其偏差值就可以得到右图坐标，然后比对两者偏差值即可。

接着便是子像素拟合。通过代价矩阵得到的视差图是整像素精度的，这在许多应用中都是无法满足需求的。这时候我们需要对得到的视差图进行子像素拟合，让视差图的精度进一步提高。其本质就是拟合一个一元二次曲线。先前我们通过偏差值选取获得了一个二维的偏差值矩阵。这个矩阵中存储着图像中每个点处的最优偏差值。但正如上文所说，这些偏差值为整数，接下来我们要做的就是以该偏差值矩阵为基础，拟合出精度更高的浮点偏差值再储存回这个矩阵里。

找到偏差值矩阵某一点的偏执值。再在cost矩阵里找到其对应点。这时，通过与它本身（d）以及与它相邻的两个偏差值d+1和d-1中，我们可以获得三个cost值d.cost、(d-1).cost、(d+1).cost。以d为横坐标，cost为纵坐标，我们就可以拟合出一个一元二次曲线。此时这个二次曲线的顶点处的x坐标，即d值就是我们拟合出来的偏差值了。接下来只要将其代回偏差值矩阵便可。

#### 遇到的问题

1.偏差值选取过程中，因为弄混最小差分代价和最高相关代价而导致图片发生失真，通过将选取最小值改为选取最大值后该问题就得到了解决

2.偏差值优化过程中，默认初始阈值设定过小，导致图像出现大片黑色图斑，将阈值调高至10后问题得到较好的解决。

3.偏差值优化中，优化后的输出图片往往莫名出现斑马条纹状的干扰。后查明是在进行左右一致性检查时，左图坐标过小时再减去偏差值其实就得到负数，进而自动移动到上一行像素点的坐标，导致左右一致性检查出错，产生了许多错误的黑块。通过增加一个if语句比对坐标值与偏差值大小即可解决

4.偏差值优化中，发现图片子像素拟合效果不明显，后发现是使用不恰当if语句所导致，更改后恢复正常。

### 性能优化

双目成像是计算量非常大的任务，在未经优化的代码上，一幅图片可能需要数分钟的时间。因此，实验中还进行了性能优化的尝试：

#### 使用适合CPU的算法

由于我们选用CPU进行计算，因此要充分选择发挥CPU顺序执行能力的算法。在NCC计算部分，我们使用了前缀和，使得求和部分的计算量和求和区域大小无关。在聚合部分，我们使用了基于图的聚合方法，这个方法对内存的要求非常高，也包含大量分支，是比较适合CPU的计算能力的。

#### 并行计算

实验中各个环节都涉及大量数值计算，这些计算都跟偏差值d关系不大，因此我们在所有遍历d的循环上都使用OMP进行了并行，充分利用CPU的多个核心。

#### 充分内联

在实验中我们发现，访问图像某一位置值的函数`Mat::at`并没有被内联，这使得大量的循环优化等没有实现。通过调整MSVC内联级别从`/O2`默认的`/Ob2`到更强的`/Ob3`，可以发现`Mat::at`被内联，使得程序速度提高了20%左右。

## 实验结果

### Middlebury 2021表现

### 自制数据集表现

## 应用背景分析或展望

