# 双目成像实验报告

## 封面

g。自己先在word里做一张，包括分工：

曾富楠：40%，程序框架和最小生成树聚合
宣思诚：30%，NCC计算及双边滤波聚合
李泽奇：30%，双目校正和偏差值优化

## 问题描述

g。程序的大体框架，参考PPT/论文/代码。

## 实现细节

### 双目标定和校正

g。

### 输入输出

本实验中使用Middlebury 2021数据集，这个数据集包括三部分

1. 测试描述，包括测试用的像素内参、图像大小、估计最大偏差值和实际最大最小偏差值（仅供验证）。
2. 双目校正后的左右图像。
3. 左右图像对应的偏差值的真值。

其中，真值使用PFM格式编码，根据http://netpbm.sourceforge.net/doc/pfm.html，这个格式包括文件开头"Pf"或者"PF"，两个代表图像尺寸的整数，一个代表大小端和缩放倍数的浮点数。上述三个数字以文本表示，结束后有一个换行符0x0A。在开头后是若干个IEEE 754 32位浮点数，直接读入`cv::Mat`的数据指针即可。但要注意的是，这个数据的原点在左下方，与OpenCV（左上）不同，需要关于x轴进行翻转。

### NCC计算

NCC（Normalized CrossCorrelation）是用于归一化待匹配目标之间的相关程度。相比于直接进行像素值相减的方法，NCC将左右像素的差距根据均值和标准差进行标准化，避免了亮度等的干扰。

这里比较的是原始像素。通过在待匹配像素位置$p$构建邻域匹配窗口，与目标像素位置$p^\prime$同样构建邻域匹配窗口的方式建立目标函数来对匹配窗口进行度量相关性。这里构建相关窗口的前提是两帧图像之间已经校正到水平位置，即光心处于同一水平线上，此时极线是水平的，否则匹配过程只能在倾斜的极线方向上完成，这会消耗更多的计算资源。
$$
C(u,v,d) = \frac{\sum_{x=u-\varrho}^{u+\varrho}\sum_{y=v-\varrho}^{v+\varrho}I_l(x,y)I_r(x-d,y)-n\mu_l\mu_r}{n\sigma_l\sigma_r}
$$
NCC部分的计算依托于左右图像的灰度值，因为RGB格式无法选择通用有效的值进行计算，因此程序在进行运算前将左右图全部转化为灰度图，所有需要调用左右图像像素值的部分调用结果均为灰度值。

#### 计算过程

式中的$\sum_{x=u-\varrho}^{u+\varrho}\sum_{y=v-\varrho}^{v+\varrho}I_l(x,y)I_r(x-d,y)$部分因为左右图的窗口值也就是像素间隔的设定始终维持在一个动态的情况下，因此这部分的计算无法通过前缀和这类优化，因此只能选择OMP进行并行运算以提高运算速度。而均值部分	$\mu_l\mu_r$和标准差$\sigma_l\sigma_r$部分则因为与窗口值无关，在整个计算的过程中维持恒定，因此可以对其进行部分优化。我们的程序使用了二维前缀和（积分图）的形式对其进行优化，在需要遍历窗口值的计算部分之前将所有均值以及标准差全部计算完成，这样就方便了后续在程序中调用。

要注意的是，前缀和必须使用整数数据类型而不是浮点数据类型。这是因为我们需要大量计算两个相邻的大数间的差距，如果使用浮点数表示，则这个差距可能因为两个数字太大而被滤去，造成非常大的误差。但计算机上的整数都是表示模$2^N$环上的数，低位不会被舍去，满足交换律和结合律，不存在误差。

式中的I代表像素强度，取值即为上述的图像灰度值，范围[0,255]。式中$\varrho$的值取8，相对扩大了像素块的大小，这样有利于保证相关度的有效性，使其更加准确。计算结果储存在三维矩阵中方便后续调用计算。

### 双边滤波

双边滤波是一种非线性的滤波方法，是结合图像的空间邻近度和像素值相似度的一种折中处理，同时考虑空域信息和灰度相似性，达到保边去噪的目的。具有简单、非迭代、局部的特点，可以做边缘保存。

#### 基本思路

同时考虑像素点的空域信息和值域信息。即先根据像素值对要用来进行滤波的邻域做一个分割或分类，采用加权平均的方法，用周边像素亮度值的加权平均代表某个像素的强度，所用的加权平均基于高斯分布。最重要的是，双边滤波的权重不仅考虑了像素的欧氏距离，还考虑了像素范围域中的辐射差异，在计算中心像素的时候同时考虑这两个权重。

在平坦区域，临近像素的像素值的差值较小，对应值域权重接近于1，此时空域权重起主要作用，相当于直接对此区域进行高斯模糊。因此，平坦区域相当于进行高斯模糊。在边缘区域，临近像素的像素值的差值较大，对应值域权重接近于0，导致此处核函数下降，当前像素受到的影响就越小，从而保持了原始图像的边缘的细节信息。

#### 计算过程

双边滤波的公式如下，其中$\omega_r$为关于$x$和$y$的正态分布，$\omega_d$为关于$I(x)$和$I(y)$的正态分布

$$
C^A(u,v,d) = \frac{\sum_{x=u-\rho}^{u+\rho}\sum_{y=v-\rho}^{v+\rho}\omega_d(x,y)\omega_r(x,y)C(x,y,d)}{\sum_{x=u-\rho}^{u+\rho}\sum_{y=v-\rho}^{v+\rho}\omega_d(x,y)\omega_r(x,y)}
$$

计算中每次选定一个像素点，并以该像素点为中心向周围扩展出一个像素块，像素块中每个像素的像素强度和中心点的像素强度差值将直接影响计算过程中的权重，最终与对应的NCC部分计算结果进行运算。以此为基本思路完成整个滤波过程。

相较于NCC部分，这部分的运算时间可能达到其十倍甚至百倍。面对如此巨大的运算量必须对其进行优化，但由式中可以看出，每一个像素块的运算结果与当前像素块中心的像素强度有关，因此像素强度的差值也会随着像素块中心点的变化而持续变化，无法使用前缀和一类的优化方案，只能对其使用OMP进行并行计算，以此来减少运算时间。即便如此，这部分的计算量依旧庞大，整个程序最终的运算时间依旧很大程度上取决于该部分的运算时间。

### 最小生成树聚合

最小生成树聚合是论文A non-local cost aggregation method for stereo matching中使用的一种类似双边滤波的聚合计算方法。这个方法的特点利用的数据结构比较复杂，但计算量很小，且表现不错，适合于CPU上进行计算。

#### 数学模型

作为一种基于生成树的图像滤波，最小生成树首先要求将像素点间的连通关系转换为生成树（spanning tree）的结构，即把图片中的像素和上下左右的相邻像素连接作为无向图，去掉若干边后，使得任意两个像素间只有一条可能的路径，且所有权重的合最小。

可以使用Prim算法计算最小生成树。按权重从小到大遍历所有边，遍历过程中，如果一条边的两端不在同一树中，则将这条边两端连接，加入生成树中，并且这条边在第二步不再遍历。对于RGB图片，权重指的是两个像素间RGB三个值的偏差中最大的一个，取值范围$[0,255]$。

构成生成树后，ST算法在全图上计算一个聚合的值：

$$
C^A(p) = \sum_{q\in I}{S(p, q)C(q)}
$$

其中$C^A(p)$为p点聚合后的cost，$C(q)$为q点聚合前的cost，$I$为图片上所有像素的集合，$S(p, q)$是图上这两个点的距离的函数，定义为

$$
S(p,q)=\exp{\left(-\frac{D(p,q)}{\sigma}\right)}
$$

$D(p,q)$为p、q两点间的距离，以生成树上这两间边的权重的和衡量。

若任意指定一个点为根节点，把生成树转换为有方向的树，则上述$C^A(p)$有一个计算量很小且递归的计算方法。定义$C^{A\uparrow}(p)=\sum_{q\in\operatorname{subtree}(p)}{S(p, q)C(q)}$为p点的子树中所有点对p点的聚合值的贡献，由于当b点在a、c两点间时，$S(a,c)=S(a,b)\cdot S(b,c)$，有方程

$$
\begin{align}
    C^{A\uparrow}(p) &= C(p) + \sum_{q\in\operatorname{child}(p)}{S(p,q)C^{A\uparrow}(q)}\\
    C^A(p) &= S(\operatorname{parent}(p),p)C^A(\operatorname{parent}(p))+(1-S(\operatorname{parent}(p),p)^2)C^{A\uparrow}(p)
\end{align}
$$

根据边界条件，p为叶节点时$C^{A\uparrow}(p)=C(p)$，可以递归地自底向上计算出各节点的$C^{A\uparrow}$，又有p为根节点时$C^A(p)=C^{A\uparrow}(p)$，可以递归地自顶向下计算出各节点的$C^A$。

#### 有向图的编码

实现上述算法重点是需要在图这样一个连接比较稀疏的结构中简单地表示边和节点，以及如何判断两个节点是否已连接。其余的过程按照Prim算法即可，生成完后再将无向图转换为有向图。

为了节约空间及更好的空间连续性可能带来的缓存性能优化，边用32位的位域表示，其中最高的8位表示权重，次高位表示是边的方向是横向还是纵向，其余的23位用于表示地址较小的像素的偏移地址，23位范围内大约可以表示4K，即3840x2160，足以满足实验的要求。权重直接嵌入到边的数据结构中，这样每次判断时不需要再去查找原图像，提高性能。

而无向图通过一个4位整数表示，四个比特分别表示上下左右四个方向上是否有相邻的边。树还需要一个额外的整数用于指示父节点的方向避免死循环，因此另有2个比特用于表示方向。

另外，判断两个点是否已连接需要使用到并查集。由于像素的偏移坐标是连续的，因此可以使用数组直接存储并查集的父节点。由于涉及非常多的查询操作，并查集只使用简单的路径压缩进行优化也可以保证性能。路径压缩即每次查找时，把查询路径上所有节点的父节点都指向最终的父节点，使得下次查询时一步即可到达。

有了上述数据结构，可以使用Prim算法计算最小生成树了：

1. 生成所有的边，即除了最右的像素都生成向右的一条边，除了最下的像素都生成向下的一条边
2. 根据权重排序这些边。由于权重的访问是完全独立的，通过`std::executaion::par_unseq`说明使用可以并行化的`std::sort`进行排序。
3. 计算最小生成树。根据权重从小到大遍历各边，通过并查集判断遍历到的边是否连接两个未连通的节点，如果是则更新无向图，把这个节点加入无向图中，同时也更新并查集反应无向图的连通状况。
4. 将最小生成树改为有向图，即任意指定一节点为根节点，深度优先遍历各节点，确定父节点的方向。

#### 聚合

建立了树之后，聚合是比较简单的，只需要根据4个方向，从根节点开始逐个遍历所有的节点，首先计算$C^{A\uparrow}($，然后再计算$C^A$即可。但需要注意的是，由于遍历的深度可能非常非常深，不能使用系统栈，而是需要手动地编写状态机，这是比较复杂的，尤其是自底向上遍历时，还需要涉及复杂的状态储存。

但需要关注的是聚合过程中的数值稳定性。在$C^A(p) = S(\operatorname{parent}(p),p)C^A(\operatorname{parent}(p))+(1-S(\operatorname{parent}(p),p)^2)C^{A\uparrow}(p)$中，$C^A(\operatorname{parent}(p))$已经包含了$C^{A\uparrow}(p)$，在后面的计算中又减去$C^{A\uparrow}(p)$，由于浮点数的取整，左右并不严格相等。但舍去部分的占比通常不大，因此可以认为左右近似相等。但要注意的是，如果cost可能是nan，则会导致整个树都是nan，这是全局滤波不可避免的。

### 偏差值优化

g。refine_disparity和choose_disparity

### 性能优化

双目成像是计算量非常大的任务，在未经优化的代码上，一幅图片可能需要数分钟的时间。因此，实验中还进行了性能优化的尝试：

#### 使用复杂度低的算法

本实验中选用的数据集为Middlebury 2021，该数据集中图像的分辨率为1920x1080，且左右偏差可达300像素，带来的计算量是非常大的。但我们使用的算法复杂度较低，减少了大尺寸图片的影响。比如我们使用了积分图优化NCC计算，这个算法的复杂度只和像素数有关，即图像尺寸放大为2倍后计算量为原来的4倍。而如果直接计算，则图像放大后相应的窗口大小也要放大，图像尺寸放大为2倍后计算量为原来的16倍。而最小生成树聚合也同样只和图像的像素数有关，图像尺寸放大为2倍后，偏差值也放大为2倍，计算量为原来的8倍，而如果是双边滤波，则滤波窗口同样要放大，计算量会变为原来的32倍。

#### 使用适合CPU的算法

由于我们选用CPU进行计算，因此要充分选择发挥CPU顺序执行能力的算法。在NCC计算部分，我们使用了前缀和，使得求和部分的计算量和求和区域大小无关。代价是前缀和的计算是高度顺序相关的，不能调换计算顺序。在聚合部分，我们使用了基于图的聚合方法，这个方法对内存的要求非常高，而且包含大量分支，是比较适合CPU的计算能力的。

#### 并行计算

实验中各个环节都涉及大量数值计算，这些计算都跟偏差值d关系不大，因此我们在所有遍历d的循环上都使用OMP进行了并行，充分利用CPU的多个核心。

#### 充分内联

在实验中我们发现，访问图像某一位置值的函数`Mat::at`并没有被内联，这使得大量的循环优化等没有实现。通过调整MSVC内联级别从`/O2`默认的`/Ob2`到更强的`/Ob3`，可以发现`Mat::at`被内联，使得程序速度提高了20%左右。

## 实验结果

### Middlebury 2021表现

### 自制数据集表现

## 应用背景分析或展望

双目视觉相较于投影式、全息照相式等三维成像技术而言，双目视觉成本更低、效率更高、结构更简单，因此在工业检测、机器人导航、医学机器成像、控制与检测位姿、军事、航空测绘等诸多领域均有广泛应用。例如构建自适应伺服系统，仿真机器人导航系统，多维度机械装置位姿检测等。相对更贴近我们日常生活的应用也有智能驾驶、虚拟现实技术方面的应用。

我们的程序计算速度较快，在Intel i7-10700 CPU上，不加左右校验时可以在3-4秒的时间计算一张1080p，左右差别200像素左右的图片，在实际应用中可以不采取清晰度这么高的图像进行计算，以Middlebury2003数据集为例，该数据集图像较小，计算量只有测试图像的1/70。同时我们的程序在计算过程中选取的窗口值范围是$[0,170]$，实际计算中窗口值范围可以有所收小，或者不必对窗口值进行连续计算，可以离散地选择其中有代表性的窗口值计算，并以此减小计算量。如果应用了上述两个方法，则计算量极大减小，可以实时进行。同时在并行计算方面，我们的程序只使用了OMP对其进行少量优化，并未使用SIMD指令，如果能增加这方面的优化，程序的运算速度还可以更上一层。

我们的程序实现了双目立体视觉算法，作为基础的三维成像技术在诸多领域均有广泛应用。同时，为了追求精度牺牲了一部分运算时间，也并未在并行程序上进行过多优化，这些问题在实际应用中可以对其进行优化以达到更快的计算时间效果。
